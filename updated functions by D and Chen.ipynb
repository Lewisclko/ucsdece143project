{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University Analysis\n",
    "\n",
    "# Group 4 \n",
    "\n",
    "### Members: Chen Lin Ko, Datzael Gomez, Eric Megrabov\n",
    "### Functions used for data cleaning and sorting\n",
    "These are the functions used for data cleaning\n",
    "\n",
    "** An quick how to use fucntions is below the functions themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names():\n",
    "    #Author: Datzael Gomez\n",
    "    #Data Dictionary Variables \n",
    "    '''\n",
    "    Because the data in excel sheet doesn't have well defined variable names it is not easy to know\n",
    "    what data is needed for the analysis, therefore an extra step is needed to \n",
    "    remove all the unnessary data and translate what each variable signifies using \n",
    "    a data dictionary that is provided. The end goal is to remove all the unecessary data and change the variable names to \n",
    "    more definite and understandable names.\n",
    "    return: df_names(list), df(dataframe)\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    #load Data dictionay using pandas\n",
    "    df_dictionary = pd.read_csv('CollegeScorecardDataDictionarydata_dictionary.csv')\n",
    "    #only want to look at variable name and their significance\n",
    "    df_translate= df_dictionary[['NAME OF DATA ELEMENT','VARIABLE NAME']]\n",
    "    #Drop any NaN inputs\n",
    "    df_translate= df_translate.dropna()\n",
    "    #save variables of interest indexes and yes thi was a long process\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('SAT')]\n",
    "    y= x.index.get_values()\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('ACT')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y= np.delete(y, 9)\n",
    "    y = np.delete(y,9)\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Total share of enrollment of undergraduate degree-seeking students')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('First-time, full-time student retention rate at four-year institutions')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Share of')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y=y[:-10]\n",
    "    y=np.delete(y,-10)\n",
    "    y=np.delete(y,-9)\n",
    "    y=np.delete(y,-8)\n",
    "    y=np.delete(y,-7)\n",
    "    y=np.delete(y,-6)\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('The median debt for')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Enrollment')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y=np.append(y,[3,4,5,6])\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Longitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Latitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y.sort()\n",
    "    #pick out the variable of interest from the big dictionary of variables\n",
    "    df= df_translate.ix[y]\n",
    "    #make a list of the variables that will be chosen from each csv file and a general data frame containing the definitions\n",
    "    #of each data frame value\n",
    "    df_names=df['VARIABLE NAME'].tolist()\n",
    "    df_names.append('INSTNM')\n",
    "    \n",
    "    return df_names, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#Ethnicity function\n",
    "def ethnicity(m, df_names, df):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    inputs: m= csvfilename of year of interest, and  [df_names, df] from the names() function.\n",
    "    This function will look at all columns related to ethnicity, remove any nan's and make a new \n",
    "    data frame for these particular values and for future mapping with the name of the institutions are attached\n",
    "    return: df_ethnic\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import pandas as pd\n",
    "    df2016 = pd.read_csv(m)\n",
    "    df2016= df2016[df_names]\n",
    "    y=[]\n",
    "    # Get all the columns of interest by their variable names taken directly from \n",
    "    df_temp= df.loc[df['VARIABLE NAME'].str.contains('UG')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df.loc[df['VARIABLE NAME'].str.contains('CITY')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df.ix[y]\n",
    "    ethnic = df_temp['VARIABLE NAME'].tolist()\n",
    "    ethnic.append('INSTNM')\n",
    "    df_ethnic = df2016[ethnic]\n",
    "    # for loop to look at \n",
    "    m=[]\n",
    "    for i in range(len(y)):\n",
    "        q = df_ethnic.loc[1].isnull()\n",
    "        if q[i] == False:\n",
    "            m=np.append(m,ethnic[i])\n",
    "    \n",
    "    \n",
    "    m=np.append(m,ethnic[len(y)])\n",
    "    \n",
    "    df_ethnic= df_ethnic[m] \n",
    "    df_ethnic = df_ethnic.dropna()\n",
    "    df_ethnic= df_ethnic.T.drop_duplicates().T\n",
    "    \n",
    "    return df_ethnic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_lat(m):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    '''\n",
    "    input:m=df_enthnic (look at ethnicity()) type: dataframe \n",
    "    This function takes in a the ethnic dataframe (df_ethnic) and then looks at the institution name  \n",
    "    and then returns the latitude and longitude of the location of the institution needed for heatmapping \n",
    "    '''\n",
    "    df_dictionary = pd.read_csv('CollegeScorecardDataDictionarydata_dictionary.csv')\n",
    "    #only want to look at variable name and their significance\n",
    "    df_translate= df_dictionary[['NAME OF DATA ELEMENT','VARIABLE NAME']]\n",
    "    #Drop any NaN inputs\n",
    "    df_translate= df_translate.dropna()\n",
    "    y=[]\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Longitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Latitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y.sort()\n",
    "    df= df_translate.ix[y]\n",
    "    df_names=df['VARIABLE NAME'].tolist()\n",
    "    df_names.append('INSTNM')\n",
    "    df2016 = pd.read_csv('MERGED2015_16_PP.csv')\n",
    "    df2016= df2016[df_names]\n",
    "    t2 = m['INSTNM'].tolist()\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    # using the data from the year 2016 a latitude longitude key was made to locate each university since universities don't move\n",
    "    for i in range(len(m['INSTNM'])):\n",
    "        e = df2016[df2016['INSTNM']== t2[i]]\n",
    "        if len(e) > 0:\n",
    "            df_t=  df2016[df2016['INSTNM']==t2[i]]\n",
    "            temp1=df_t['LONGITUDE'].tolist()\n",
    "            temp2=df_t['LATITUDE'].tolist()\n",
    "            l1.append(temp1[0])\n",
    "            l2.append(temp2[0])\n",
    "        else:\n",
    "            l1.append(0)\n",
    "            l2.append(0)\n",
    "        \n",
    "    dft= pd.DataFrame({'LONGITUDE':l1,'LATITUDE':l2})\n",
    "    df_longlat= pd.concat([dft, m],axis=1, join_axes=[dft.index])\n",
    "    \n",
    "    return df_longlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#debt by state function\n",
    "def debt_by_state(m, df_names, df1):\n",
    "    '''\n",
    "    input: m= csvfilename of year of interest, and  [df_names, df] from the names() function.\n",
    "    this function will look at all columns related to debt and remove any rows that have a privacysuppressed value \n",
    "    and make a new data frame that then returns the state and amount of debt of the universities.\n",
    "    output: df_debt type: dataFrame\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv(m)\n",
    "    df= df[df_names]\n",
    "    y=[]\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('DEBT')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('STABBR')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df1.ix[y]\n",
    "    col = df_temp['VARIABLE NAME'].tolist()\n",
    "    df_debt = df[col]\n",
    "    len(y)\n",
    "    m=[]\n",
    "    for i in range(len(y)):\n",
    "        q= col\n",
    "        df_debt=df_debt[df_debt[q[i]] != 'PrivacySuppressed'] \n",
    "    df_d= df_debt[m]  \n",
    "    df_d = df_d.dropna()\n",
    "\n",
    "    \n",
    "    return df_debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "# Finding average student debt of year in question\n",
    "def debtAvg(m):\n",
    "    '''\n",
    "    Input: csvfilename of year of interest\n",
    "    This function using the debt_by_state function calculates the average student debt in each state and returns a data\n",
    "    frame of the average debt and state.\n",
    "    Output: df_avg\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df_names, df1 = names()\n",
    "    x= debt_by_state(m, df_names, df1)\n",
    "    acm=[]\n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "              \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "              \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "              \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "              \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "    for i in range(len(states)):\n",
    "        dft= x[x['STABBR']== states[i]]\n",
    "        dft = dft.dropna()\n",
    "        if sum(map(float,dft['GRAD_DEBT_MDN'].tolist())) != 0:\n",
    "            acm.append(int(sum(map(float,dft['GRAD_DEBT_MDN'].tolist()))/len(dft['GRAD_DEBT_MDN'].tolist())))\n",
    "        else: \n",
    "            acm.append(sum(map(int,dft['GRAD_DEBT_MDN'].tolist())))\n",
    "    \n",
    "        \n",
    "    df_avg=[states,acm]\n",
    "    df_avg=pd.DataFrame(df_avg)\n",
    "\n",
    "    df_avg= df_avg.transpose()\n",
    "\n",
    "    df_avg=df_avg.rename(index=str, columns={0:\"States\", 1:\"Cumulative debt\"})\n",
    "    \n",
    "    return df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#Finding the average change in debt from between the years 2010-2016\n",
    "def avgchangedebt():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    '''\n",
    "    No input needed\n",
    "    This function will calculate the change of student from between the years 2010 to 2016 to show whether tuition has increased\n",
    "    or decreased. a dataframe is returned of the state and the amount of average increase/decrease of student debt each year\n",
    "    between 2010-2016\n",
    "    Output: dftemp type dataframe\n",
    "    '''\n",
    "    tests=['MERGED2010_11_PP.csv','MERGED2011_12_PP.csv','MERGED2012_13_PP.csv','MERGED2013_14_PP.csv',\n",
    "           'MERGED2014_15_PP.csv','MERGED2015_16_PP.csv']\n",
    "    for i in range(len(tests)-1):\n",
    "        a=debtAvg(tests[i])\n",
    "        b=debtAvg(tests[i+1])\n",
    "        if i == 0:\n",
    "            dftemp= b.set_index('States').subtract(a.set_index('States'), fill_value=0)\n",
    "        else:\n",
    "            dftemp= dftemp.add(b.set_index('States').subtract(a.set_index('States'), fill_value=0),fill_value=0)\n",
    "    dftemp.divide(len(tests)-1)\n",
    "    return dftemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#SAT function\n",
    "def SAT(m, df_names, df1):\n",
    "    '''\n",
    "    input: m= csvfilename of year of interest, and  [df_names, df] from the names() function.\n",
    "    This function will look at all columns related to SAT scores and remove any nan's and make a new data frame\n",
    "    of the SAT scores of each institution distinguised by state.\n",
    "    output: df_sat type dataframe\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(m)\n",
    "    df= df[df_names]\n",
    "    y=[]\n",
    "    h=[]\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('STABBR')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('SAT')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df1.ix[y]\n",
    "    col = df_temp['VARIABLE NAME'].tolist()\n",
    "    df_sat = df[col]\n",
    "    df_sat = df_sat.dropna()\n",
    "    \n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "    \n",
    "    q=0\n",
    "    for i in range(len(states)):\n",
    "         q = np.append(q,df_sat[df_sat['STABBR']== states[i]].index.get_values())\n",
    "            \n",
    "    q.sort()\n",
    "    df_sat= df_sat.ix[q]\n",
    "    return df_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#ACT function\n",
    "def ACT(m, df_names, df1):\n",
    "    '''\n",
    "    input: m= csvfilename of year of interest, and  [df_names, df] from the names() function\n",
    "    This function will look at all columns related to ACT scores and remove any nan's and make a new data frame\n",
    "    of the ACT scores of each institution distinguised by state\n",
    "    output: df_act type dataFrame\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv(m)\n",
    "    df= df[df_names]\n",
    "    y=[]\n",
    "    h=[]\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('STABBR')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('ACT')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df1.ix[y]\n",
    "    col = df_temp['VARIABLE NAME'].tolist()\n",
    "    df_act = df[col]\n",
    "    df_act = df_act.dropna()\n",
    "    \n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "    \n",
    "    q=0\n",
    "    for i in range(len(states)):\n",
    "         q = np.append(q,df_act[df_act['STABBR']== states[i]].index.get_values())\n",
    "            \n",
    "    q.sort()\n",
    "    df_act= df_act.ix[q]\n",
    "    return df_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael\n",
    "#ACT averages\n",
    "def ACTavg(m):\n",
    "    '''\n",
    "    input: m=csvfilename of year of interest\n",
    "    This function will take in the dataframe from the ACT function and find the average \n",
    "    ACT cumulative score. the output will be a data frame of the average cululative score \n",
    "    of the 25, 75 percentile and the midpoint.\n",
    "    output: df_act_avg type dataFrame \n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df_names, df1 = names()\n",
    "    x= ACT(m, df_names, df1)\n",
    "    acm=[]\n",
    "    ac25=[]\n",
    "    ac75=[]\n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "              \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "              \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "              \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "              \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "    for i in range(len(states)):\n",
    "        dft= x[x['STABBR']== states[i]]\n",
    "        if sum(dft['ACTCMMID'].tolist()) != 0:\n",
    "            acm.append(sum(dft['ACTCMMID'].tolist())/len(dft['ACTCMMID'].tolist()))\n",
    "        else: \n",
    "            acm.append(sum(dft['ACTCMMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['ACTCM25'].tolist()) != 0:\n",
    "            ac25.append(sum(dft['ACTCM25'].tolist())/len(dft['ACTCM25'].tolist()))\n",
    "        else: \n",
    "            ac25.append(sum(dft['ACTCM25'].tolist()))\n",
    "    \n",
    "        if sum(dft['ACTCM75'].tolist()) != 0:\n",
    "            ac75.append(sum(dft['ACTCM75'].tolist())/len(dft['ACTCM75'].tolist()))\n",
    "        else: \n",
    "            ac75.append(sum(dft['ACTCM75'].tolist()))\n",
    "    \n",
    "        \n",
    "    df_act_avg=[states,acm,ac25,ac75]\n",
    "    df_act_avg=pd.DataFrame(df_act_avg)\n",
    "\n",
    "    df_act_avg= df_act_avg.transpose()\n",
    "\n",
    "    df_act_avg=df_act_avg.rename(index=str, columns={0:\"States\", 1:\"Cumulative Mid\",2:\"Cumulative 25\",\n",
    "                                                     3:\"Cumulative 75\"})\n",
    "    \n",
    "    return df_act_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael\n",
    "#SAT averages\n",
    "def SATavg(m):\n",
    "    '''\n",
    "    input: m=csvfilename of year of interest\n",
    "    This function will take in the dataframe from the SAT function and find the average \n",
    "    SAT scores math,writing,reading. the output will be a data frame of the average cululative score \n",
    "    of the 25, 75 percentile and the midpoint.\n",
    "    output: df_sat_avg type dataFrame \n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df_names, df1 = names()\n",
    "    x= SAT(m, df_names, df1)\n",
    "    srm=[]\n",
    "    sr25=[]\n",
    "    sr75=[]\n",
    "    smm=[]\n",
    "    sm25=[]\n",
    "    sm75=[]\n",
    "    swm=[]\n",
    "    sw25=[]\n",
    "    sw75=[]\n",
    "    r=[]\n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "              \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "              \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "              \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "              \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "    for i in range(len(states)):\n",
    "        dft= x[x['STABBR']== states[i]]\n",
    "        if sum(dft['SATVRMID'].tolist()) != 0:\n",
    "            srm.append(sum(dft['SATVRMID'].tolist())/len(dft['SATVRMID'].tolist()))\n",
    "        else: \n",
    "            srm.append(sum(dft['SATVRMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATMTMID'].tolist()) != 0:\n",
    "            smm.append(sum(dft['SATMTMID'].tolist())/len(dft['SATMTMID'].tolist()))\n",
    "        else: \n",
    "            smm.append(sum(dft['SATMTMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATWRMID'].tolist()) != 0:\n",
    "            swm.append(sum(dft['SATWRMID'].tolist())/len(dft['SATWRMID'].tolist()))\n",
    "        else: \n",
    "            swm.append(sum(dft['SATWRMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATVR25'].tolist()) != 0:\n",
    "            sr25.append(sum(dft['SATVR25'].tolist())/len(dft['SATVR25'].tolist()))\n",
    "        else: \n",
    "            sr25.append(sum(dft['SATVR25'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATMTMID'].tolist()) != 0:\n",
    "            sm25.append(sum(dft['SATMT25'].tolist())/len(dft['SATMT25'].tolist()))\n",
    "        else: \n",
    "            sm25.append(sum(dft['SATMT25'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATWR25'].tolist()) != 0:\n",
    "            sw25.append(sum(dft['SATWR25'].tolist())/len(dft['SATWR25'].tolist()))\n",
    "        else: \n",
    "            sw25.append(sum(dft['SATWR25'].tolist()))\n",
    "        \n",
    "        if sum(dft['SATVR75'].tolist()) != 0:\n",
    "            sr75.append(sum(dft['SATVR75'].tolist())/len(dft['SATVR75'].tolist()))\n",
    "        else: \n",
    "            sr75.append(sum(dft['SATVR75'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATMTMID'].tolist()) != 0:\n",
    "            sm75.append(sum(dft['SATMT75'].tolist())/len(dft['SATMT75'].tolist()))\n",
    "        else: \n",
    "            sm75.append(sum(dft['SATMT75'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATWRMID'].tolist()) != 0:\n",
    "            sw75.append(sum(dft['SATWR75'].tolist())/len(dft['SATWR75'].tolist()))\n",
    "        else: \n",
    "            sw75.append(sum(dft['SATWR75'].tolist()))\n",
    "        \n",
    "    df_sat_avg=[states,srm,sr25,sr75,smm,sm25,sm75,swm,sw25,sw75]\n",
    "    df_sat_avg=pd.DataFrame(df_sat_avg)\n",
    "\n",
    "    df_sat_avg= df_sat_avg.transpose()\n",
    "\n",
    "    df_sat_avg=df_sat_avg.rename(index=str, columns={0:\"States\", 1:\"Reading Mid\",2:\"Reading 25\",\n",
    "                                                     3:\"Reading 75\",4:\"Math Mid\",5:\"Math 25\",6:\"Math 75\",\n",
    "                                                     7:\"Writing Mid\",8:\"Writing 25\",9:\"Writing 75\"})\n",
    "    \n",
    "    return df_sat_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the needed data\n",
    "### Below is how to use the functions to get the needed data\n",
    "In order to get the data frame needed to plot  heat maps of each ethnicity in college\n",
    "these functions must be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ethnic data frame of population numbers\n",
    "ethnicity(m, df_names, df)\n",
    "#geocodes for the long/latitude coordinates for the location of each university for plotting\n",
    "long_lat(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the average SAT/ACT scores for each state the following functions are used to ge the necessary dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average cumulative ACT scores by state\n",
    "ACTavg(m)\n",
    "#average cumulative SAT scores by state\n",
    "SATavg(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the data frame needed to plot the average student and the average increase/decrease of student debt between the \n",
    "years 2010 and 2016 the following functions were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average debt by state\n",
    "debtAvg(m)\n",
    "#increase/decrease debt per year\n",
    "avgchangedebt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build up visualized graphs from data\n",
    "\n",
    "Heat map plotting funcitons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9be7c7c90a4662b52dec74b5d04610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure(layout=FigureLayout(height=u'420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Auther: Chen-Lin Ko\n",
    "Require gmpas module which include interactive google maps in python notebook.\n",
    "gmaps module need support from google API keys. \n",
    "Here are example for heat maps plotting.\n",
    "'''\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "gmaps.configure(api_key=\"AIzaSyCAWylCmW-8d_LHSDfQVtYRbL2G2_7sHBA\")\n",
    "# fill in with your Google API key\n",
    "\n",
    "locations = gmaps.datasets.load_dataset(\"taxi_rides\")\n",
    "#input takes numpy arrays of actual locations\n",
    "\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(gmaps.heatmap_layer(locations))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auther: Chen-Lin Ko\n",
    "import gmaps\n",
    "gmaps.configure(api_key='AIzaSyDtjQ2F7bVjLOoz21Vseach7R26Q5CBfPI') # Fill in with your API key\n",
    "\n",
    "def heatmap_race(plotdf, race = 'UGDS_BLACK'):\n",
    "    '''\n",
    "    input plotdf: ethnicity(data_file)\n",
    "    input race: str type. It need to be one of the column of poltdf dataframe.\n",
    "    This function will translate inputs and return heat map of different races on goole map.\n",
    "    '''\n",
    "    assert isinstance(race, str)\n",
    "    locations = plotdf[['LATITUDE','LONGITUDE']]\n",
    "    weights = plotdf[race]\n",
    "    fig = gmaps.figure()\n",
    "    fig.add_layer(gmaps.heatmap_layer(locations, weights=weights,max_intensity=30, point_radius=5))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example, heat map for year 2015_2016 based on white races\n",
    "df = ethnicity('MERGED2015_16_PP.csv', df_names, df1)\n",
    "heatmap_race(df,race = 'UGDS_WHITE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar chart plotting function for SAT/ACT score by different states in US to visualize states \n",
    "with better performance in terms of SAT/ACT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Auther: Chen-Lin Ko\n",
    "barchat functoin for pandas dataframe on certain columns\n",
    "Require pandas module for data structures and data analysis\n",
    "'''\n",
    "import pandas as pd\n",
    "def barchart_score(df,col):\n",
    "    '''\n",
    "    input df: SATavg() or ACTavg(); input type: pandas dataframe\n",
    "    input col: column of pandas dataframe; input type: string\n",
    "    This funcion will plot bar chart of scores on each states\n",
    "    '''\n",
    "    assert isinstance(col,str)\n",
    "    return df.sort_values(col, ascending=False).plot.bar(x='States',y=col,rot=0,figsize=(20,10), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Auther: Chen-Lin Ko\n",
    "SAT barchat plotting\n",
    "Columns including (75, Mid, 25) in three subjects (Reading, Math, Writing)\n",
    "'''\n",
    "df = SATavg('MERGED2015_16_PP.csv')  \n",
    "#input files for different years of academic performance in SAT from each states\n",
    "\n",
    "barchart_score(df,col='Reading Mid')\n",
    "barchart_score(df,col='Math Mid')\n",
    "barchart_score(df,col='Writing Mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "auther: Chen-Lin Ko\n",
    "ACT score plotting \n",
    "Columns including Cumulative 75, Cumulative Mid,Cumulative 25\n",
    "'''\n",
    "df = ACTavg('MERGED2010_11_PP.csv')\n",
    "barchart_score(df,col='Cumulative Mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar chart plotting function for average debt of each year by different states in US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Auther: Chen-Lin Ko\n",
    "barchat functoin for pandas dataframe on certain columns\n",
    "Require pandas module for data structures and data analysis\n",
    "'''\n",
    "import pandas as pd\n",
    "def barchart_debt(df,col='Cumulative debt'):\n",
    "    assert isinstance(col,str)\n",
    "    return df.sort_values(col, ascending=False).plot.bar(x='States',y=col,rot=0,figsize=(20,10), fontsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Auther: Chen-Lin Ko\n",
    "average debt of each year barchat plotting\n",
    "'''\n",
    "fname = 'MERGED2015_16_PP.csv'\n",
    "drawingbarchart(debtAvg(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar chart plotting function for average change in student debt of each year by different states in US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Auther: Chen-Lin Ko\n",
    "barchat functoin for pandas dataframe on certain columns\n",
    "Require pandas module for data structures and data analysis\n",
    "'''\n",
    "import pandas as pd\n",
    "def barchart_debtchange(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    col='Cumulative debt'\n",
    "    return df.sort_values(col, ascending=False).plot.bar(x='States',y=col,rot=0,figsize=(25,10), fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot average change in debt\n",
    "df = avgchangedebt()\n",
    "barchart_debtchange(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
