{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names():\n",
    "    #Author: Datzael Gomez\n",
    "    #Data Dictionary Variables \n",
    "    '''\n",
    "    Because the data in excel sheet doesn't have well defined variable names it is not easy to know\n",
    "    what data is needed for the analysis, therefore an extra step is needed to \n",
    "    remove all the unnessary data and translate what each variable signifies using \n",
    "    a data dictionary that is provided. The end goal is to remove all the unecessary data and change the variable names to \n",
    "    more definite and understandable names.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    #load Data dictionay using pandas\n",
    "    df_dictionary = pd.read_csv('CollegeScorecardDataDictionarydata_dictionary.csv')\n",
    "    #only want to look at variable name and their significance\n",
    "    df_translate= df_dictionary[['NAME OF DATA ELEMENT','VARIABLE NAME']]\n",
    "    #Drop any NaN inputs\n",
    "    df_translate= df_translate.dropna()\n",
    "    #save variable indexes\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('SAT')]\n",
    "    y= x.index.get_values()\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('ACT')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y= np.delete(y, 9)\n",
    "    y = np.delete(y,9)\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Total share of enrollment of undergraduate degree-seeking students')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('First-time, full-time student retention rate at four-year institutions')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Share of')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y=y[:-10]\n",
    "    y=np.delete(y,-10)\n",
    "    y=np.delete(y,-9)\n",
    "    y=np.delete(y,-8)\n",
    "    y=np.delete(y,-7)\n",
    "    y=np.delete(y,-6)\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('The median debt for')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Enrollment')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y=np.append(y,[3,4,5,6])\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Longitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Latitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y.sort()\n",
    "    df= df_translate.ix[y]\n",
    "    df_names=df['VARIABLE NAME'].tolist()\n",
    "    df_names.append('INSTNM')\n",
    "    \n",
    "    return df_names, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#Ethnicity function\n",
    "def ethnicity(m, df_names, df):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    this function will look at all columns related to ethnicity and remove any nan's and make a new data frame with the \n",
    "    name of the institution attached.\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import pandas as pd\n",
    "    df2016 = pd.read_csv(m)\n",
    "    df2016= df2016[df_names]\n",
    "    y=[]\n",
    "    # Get all the columns of interest by their variable names taken directly from \n",
    "    df_temp= df.loc[df['VARIABLE NAME'].str.contains('UG')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df.loc[df['VARIABLE NAME'].str.contains('CITY')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df.ix[y]\n",
    "    ethnic = df_temp['VARIABLE NAME'].tolist()\n",
    "    ethnic.append('INSTNM')\n",
    "    df_ethnic = df2016[ethnic]\n",
    "    len(y)\n",
    "    m=[]\n",
    "    for i in range(len(y)):\n",
    "        q = df_ethnic.loc[1].isnull()\n",
    "        if q[i] == False:\n",
    "            m=np.append(m,ethnic[i])\n",
    "    \n",
    "    \n",
    "    m=np.append(m,ethnic[len(y)])\n",
    "    \n",
    "    df_ethnic= df_ethnic[m] \n",
    "    df_ethnic = df_ethnic.dropna()\n",
    "    df_ethnic= df_ethnic.T.drop_duplicates().T\n",
    "    return df_ethnic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_lat(m):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    '''\n",
    "    This function takes in a data an then returns the \n",
    "    '''\n",
    "    df_dictionary = pd.read_csv('CollegeScorecardDataDictionarydata_dictionary.csv')\n",
    "    #only want to look at variable name and their significance\n",
    "    df_translate= df_dictionary[['NAME OF DATA ELEMENT','VARIABLE NAME']]\n",
    "    #Drop any NaN inputs\n",
    "    df_translate= df_translate.dropna()\n",
    "    y=[]\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Longitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    x= df_translate.loc[df_translate['NAME OF DATA ELEMENT'].str.contains('Latitude')]\n",
    "    y=np.append(y,x.index.get_values())\n",
    "    y.sort()\n",
    "    df= df_translate.ix[y]\n",
    "    df_names=df['VARIABLE NAME'].tolist()\n",
    "    df_names.append('INSTNM')\n",
    "    df2016 = pd.read_csv('MERGED2015_16_PP.csv')\n",
    "    df2016= df2016[df_names]\n",
    "    t2 = m['INSTNM'].tolist()\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in range(len(m['INSTNM'])):\n",
    "        e = df2016[df2016['INSTNM']== t2[i]]\n",
    "        if len(e) > 0:\n",
    "            df_t=  df2016[df2016['INSTNM']==t2[i]]\n",
    "            temp1=df_t['LONGITUDE'].tolist()\n",
    "            temp2=df_t['LATITUDE'].tolist()\n",
    "            l1.append(temp1[0])\n",
    "            l2.append(temp2[0])\n",
    "        else:\n",
    "            l1.append(0)\n",
    "            l2.append(0)\n",
    "        \n",
    "    dft= pd.DataFrame({'LONGITUDE':l1,'LATITUDE':l2})\n",
    "    df_longlat= pd.concat([dft, m],axis=1, join_axes=[dft.index])\n",
    "    return df_longlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debt stuff\n",
    "#Author: Datzael Gomez\n",
    "#debt function\n",
    "def debt(m, df_names, df1):\n",
    "    '''\n",
    "    this function will look at all columns related to debt and remove any rows that have a privacysuppressed value \n",
    "    and make a new data frame\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv(m)\n",
    "    df= df[df_names]\n",
    "    y=[]\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('DEBT')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('CITY')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('INSTNM')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('STABBR')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df1.ix[y]\n",
    "    col = df_temp['VARIABLE NAME'].tolist()\n",
    "    df_debt = df[col]\n",
    "    len(y)\n",
    "    m=[]\n",
    "    for i in range(len(y)):\n",
    "        q= col\n",
    "        df_debt=df_debt[df_debt[q[i]] != 'PrivacySuppressed'] \n",
    "    df_d= df_debt[m]  \n",
    "    df_d = df_d.dropna()\n",
    "    \n",
    "    \n",
    "    return df_debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debt stuff\n",
    "#Author: Datzael Gomez\n",
    "#debt function\n",
    "def debt_by_state(m, df_names, df1):\n",
    "    '''\n",
    "    this function will look at all columns related to debt and remove any rows that have a privacysuppressed value \n",
    "    and make a new data frame\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv(m)\n",
    "    df= df[df_names]\n",
    "    y=[]\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('DEBT')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('STABBR')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df1.ix[y]\n",
    "    col = df_temp['VARIABLE NAME'].tolist()\n",
    "    df_debt = df[col]\n",
    "    len(y)\n",
    "    m=[]\n",
    "    for i in range(len(y)):\n",
    "        q= col\n",
    "        df_debt=df_debt[df_debt[q[i]] != 'PrivacySuppressed'] \n",
    "    df_d= df_debt[m]  \n",
    "    df_d = df_d.dropna()\n",
    "\n",
    "    \n",
    "    return df_debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debtAvg(m):\n",
    "    import pandas as pd\n",
    "    df_names, df1 = names()\n",
    "    x= debt_by_state(m, df_names, df1)\n",
    "    acm=[]\n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "              \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "              \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "              \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "              \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "    for i in range(len(states)):\n",
    "        dft= x[x['STABBR']== states[i]]\n",
    "        dft = dft.dropna()\n",
    "        if sum(map(float,dft['GRAD_DEBT_MDN'].tolist())) != 0:\n",
    "            acm.append(int(sum(map(float,dft['GRAD_DEBT_MDN'].tolist()))/len(dft['GRAD_DEBT_MDN'].tolist())))\n",
    "        else: \n",
    "            acm.append(sum(map(int,dft['GRAD_DEBT_MDN'].tolist())))\n",
    "    \n",
    "        \n",
    "    df_avg=[states,acm]\n",
    "    df_avg=pd.DataFrame(df_avg)\n",
    "\n",
    "    df_avg= df_avg.transpose()\n",
    "\n",
    "    df_avg=df_avg.rename(index=str, columns={0:\"States\", 1:\"Cumulative debt\"})\n",
    "    \n",
    "    return df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#SAT function\n",
    "def SAT(m, df_names, df1):\n",
    "    '''\n",
    "    this function will look at all columns related to SAT scores and remove any nan's and make a new data frame\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(m)\n",
    "    df= df[df_names]\n",
    "    y=[]\n",
    "    h=[]\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('STABBR')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('SAT')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df1.ix[y]\n",
    "    col = df_temp['VARIABLE NAME'].tolist()\n",
    "    df_sat = df[col]\n",
    "    df_sat = df_sat.dropna()\n",
    "    \n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "    \n",
    "    q=0\n",
    "    for i in range(len(states)):\n",
    "         q = np.append(q,df_sat[df_sat['STABBR']== states[i]].index.get_values())\n",
    "            \n",
    "    q.sort()\n",
    "    df_sat= df_sat.ix[q]\n",
    "    return df_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael Gomez\n",
    "#ACT function\n",
    "def ACT(m, df_names, df1):\n",
    "    '''\n",
    "    this function will look at all columns related to ACT scores and remove any nan's and make a new data frame\n",
    "    '''\n",
    "    assert isinstance(m,basestring), 'string type only'\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(m)\n",
    "    df= df[df_names]\n",
    "    y=[]\n",
    "    h=[]\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('STABBR')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    df_temp= df1.loc[df1['VARIABLE NAME'].str.contains('ACT')]\n",
    "    y=np.append(y,df_temp.index.get_values())\n",
    "    y.sort()\n",
    "    df_temp= df1.ix[y]\n",
    "    col = df_temp['VARIABLE NAME'].tolist()\n",
    "    df_act = df[col]\n",
    "    df_act = df_act.dropna()\n",
    "    \n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "    \n",
    "    q=0\n",
    "    for i in range(len(states)):\n",
    "         q = np.append(q,df_act[df_act['STABBR']== states[i]].index.get_values())\n",
    "            \n",
    "    q.sort()\n",
    "    df_act= df_act.ix[q]\n",
    "    return df_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael\n",
    "#ACT averages\n",
    "'''\n",
    "this function will take in the dataframe from the ACT function and find the average \n",
    "ACT cumulative score\n",
    "'''\n",
    "def ACTavg(m):\n",
    "    df_names, df1 = names()\n",
    "    x= ACT(m, df_names, df1)\n",
    "    acm=[]\n",
    "    ac25=[]\n",
    "    ac75=[]\n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "              \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "              \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "              \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "              \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "    for i in range(len(states)):\n",
    "        dft= x[x['STABBR']== states[i]]\n",
    "        if sum(dft['ACTCMMID'].tolist()) != 0:\n",
    "            acm.append(sum(dft['ACTCMMID'].tolist())/len(dft['ACTCMMID'].tolist()))\n",
    "        else: \n",
    "            acm.append(sum(dft['ACTCMMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['ACTCM25'].tolist()) != 0:\n",
    "            ac25.append(sum(dft['ACTCM25'].tolist())/len(dft['ACTCM25'].tolist()))\n",
    "        else: \n",
    "            ac25.append(sum(dft['ACTCM25'].tolist()))\n",
    "    \n",
    "        if sum(dft['ACTCM75'].tolist()) != 0:\n",
    "            ac75.append(sum(dft['ACTCM75'].tolist())/len(dft['ACTCM75'].tolist()))\n",
    "        else: \n",
    "            ac75.append(sum(dft['ACTCM75'].tolist()))\n",
    "    \n",
    "        \n",
    "    df_act_avg=[states,acm,ac25,ac75]\n",
    "    df_act_avg=pd.DataFrame(df_act_avg)\n",
    "\n",
    "    df_act_avg= df_act_avg.transpose()\n",
    "\n",
    "    df_act_avg=df_act_avg.rename(index=str, columns={0:\"States\", 1:\"Cumulative Mid\",2:\"Cumulative 25\",\n",
    "                                                     3:\"Cumulative 75\"})\n",
    "    \n",
    "    return df_act_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Datzael\n",
    "#SAT averages\n",
    "'''\n",
    "this function will take in the dataframe from the SAT function and find the average \n",
    "SAT score of each subject\n",
    "'''\n",
    "def SATavg(m):\n",
    "    df_names, df1 = names()\n",
    "    x= SAT(m, df_names, df1)\n",
    "    srm=[]\n",
    "    sr25=[]\n",
    "    sr75=[]\n",
    "    smm=[]\n",
    "    sm25=[]\n",
    "    sm75=[]\n",
    "    swm=[]\n",
    "    sw25=[]\n",
    "    sw75=[]\n",
    "    r=[]\n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "\n",
    "              \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "\n",
    "              \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "\n",
    "              \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "\n",
    "              \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "    for i in range(len(states)):\n",
    "        dft= x[x['STABBR']== states[i]]\n",
    "        if sum(dft['SATVRMID'].tolist()) != 0:\n",
    "            srm.append(sum(dft['SATVRMID'].tolist())/len(dft['SATVRMID'].tolist()))\n",
    "        else: \n",
    "            srm.append(sum(dft['SATVRMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATMTMID'].tolist()) != 0:\n",
    "            smm.append(sum(dft['SATMTMID'].tolist())/len(dft['SATMTMID'].tolist()))\n",
    "        else: \n",
    "            smm.append(sum(dft['SATMTMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATWRMID'].tolist()) != 0:\n",
    "            swm.append(sum(dft['SATWRMID'].tolist())/len(dft['SATWRMID'].tolist()))\n",
    "        else: \n",
    "            swm.append(sum(dft['SATWRMID'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATVR25'].tolist()) != 0:\n",
    "            sr25.append(sum(dft['SATVR25'].tolist())/len(dft['SATVR25'].tolist()))\n",
    "        else: \n",
    "            sr25.append(sum(dft['SATVR25'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATMTMID'].tolist()) != 0:\n",
    "            sm25.append(sum(dft['SATMT25'].tolist())/len(dft['SATMT25'].tolist()))\n",
    "        else: \n",
    "            sm25.append(sum(dft['SATMT25'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATWR25'].tolist()) != 0:\n",
    "            sw25.append(sum(dft['SATWR25'].tolist())/len(dft['SATWR25'].tolist()))\n",
    "        else: \n",
    "            sw25.append(sum(dft['SATWR25'].tolist()))\n",
    "        \n",
    "        if sum(dft['SATVR75'].tolist()) != 0:\n",
    "            sr75.append(sum(dft['SATVR75'].tolist())/len(dft['SATVR75'].tolist()))\n",
    "        else: \n",
    "            sr75.append(sum(dft['SATVR75'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATMTMID'].tolist()) != 0:\n",
    "            sm75.append(sum(dft['SATMT75'].tolist())/len(dft['SATMT75'].tolist()))\n",
    "        else: \n",
    "            sm75.append(sum(dft['SATMT75'].tolist()))\n",
    "    \n",
    "        if sum(dft['SATWRMID'].tolist()) != 0:\n",
    "            sw75.append(sum(dft['SATWR75'].tolist())/len(dft['SATWR75'].tolist()))\n",
    "        else: \n",
    "            sw75.append(sum(dft['SATWR75'].tolist()))\n",
    "        \n",
    "    df_sat_avg=[states,srm,sr25,sr75,smm,sm25,sm75,swm,sw25,sw75]\n",
    "    df_sat_avg=pd.DataFrame(df_sat_avg)\n",
    "\n",
    "    df_sat_avg= df_sat_avg.transpose()\n",
    "\n",
    "    df_sat_avg=df_sat_avg.rename(index=str, columns={0:\"States\", 1:\"Reading Mid\",2:\"Reading 25\",\n",
    "                                                     3:\"Reading 75\",4:\"Math Mid\",5:\"Math 25\",6:\"Math 75\",\n",
    "                                                     7:\"Writing Mid\",8:\"Writing 25\",9:\"Writing 75\"})\n",
    "    \n",
    "    return df_sat_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
